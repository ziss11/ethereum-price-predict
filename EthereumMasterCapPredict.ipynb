{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EthereumMasterCapPredict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Clone Git**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Clone git agar dapat load data langsung dari git repository. Dataset yang digunakan didapat kan dari kaggle: https://www.kaggle.com/datasets/sudalairajkumar/cryptocurrencypricehistory?select=coin_Ethereum.csv"
      ],
      "metadata": {
        "id": "F4hfhfPziDeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ziszz/ethereum-price-predict.git"
      ],
      "metadata": {
        "id": "n0FhqXRrTULS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Library**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Import beberapa library yang diperlukan untuk analisa data, visualisasi data dan melatih model"
      ],
      "metadata": {
        "id": "YsvDZq9MipPI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxWS4PQUj2ph"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Loading**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ECwqhw2Wj9k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/ethereum-price-predict/dataset/coin_Ethereum.csv'\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df"
      ],
      "metadata": {
        "id": "QuA1DFdKTSa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory Data** \n",
        "\n",
        "---\n",
        "\n",
        "### **Variabel-variabel pada dataset adalah sebagai berikut:**\n",
        "\n",
        "* Name: Nama mata uang kripto\n",
        "* Symbol: Simbol mata uang kripto\n",
        "* Date: Tanggal pencatatan data\n",
        "* High : Harga tertinggi pada hari tertentu\n",
        "* Low : Harga terendah pada hari tertentu\n",
        "* Open : Harga pembukaan pada hari tertentu\n",
        "* Close : Harga penutupan pada hari tertentu\n",
        "* Volume : Volume transaksi pada hari tertentu\n",
        "* Mastercap : Kapitalisasi pasar dalam USD"
      ],
      "metadata": {
        "id": "QCV7kwmxloIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mengecek informasi pada data**\n",
        "\n",
        "Melakukan pengecekan apakah terdapat missing value pada data dan kesesuaian tipe data"
      ],
      "metadata": {
        "id": "kUxdAiqwoO8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FjFSzoW_5EIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dapat dilihat bahwa tidak terdapat missing value pada dataset"
      ],
      "metadata": {
        "id": "ugX3G9ErrYpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Informasi Statistik**\n",
        "Data di atas memiliki beberapa informasi statistik pada masing-masing kolom, antara lain:\n",
        "\n",
        "* count adalah jumlah sampel pada data.\n",
        "* mean adalah nilai rata-rata.\n",
        "* std adalah standar deviasi.\n",
        "* min yaitu nilai minimum setiap kolom.\n",
        "* 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.\n",
        "* 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).\n",
        "* 75% adalah kuartil ketiga.\n",
        "* Max adalah nilai maksimum\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aV_-VzbWqXfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "TeDA3YueT3Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dapat dilihat pada visualisasi data dibawah. Terdapat banyak data outlier pada masing masing kolom data."
      ],
      "metadata": {
        "id": "czSPDLuNsQZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = df.select_dtypes(include=np.number).columns.tolist()\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "for i, col in enumerate(numeric_features):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  df.boxplot(column=col)"
      ],
      "metadata": {
        "id": "RleWRZFmfcTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terdapat beberapa teknik untuk mengatasi outlier pada data. Pada project ini akan menerapkan teknik IQR Method yaitu dengan menghapus data yang berada diluar interquartile range. Interquartile merupakan range diantara kuartil pertama(25%) dan kuartil ketiga(75%)."
      ],
      "metadata": {
        "id": "Ff67rXGusZk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df.quantile(.25)\n",
        "Q3 = df.quantile(.75)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "bot_treshold = Q1 - 1.5 * IQR\n",
        "top_treshold = Q3 + 1.5 * IQR\n",
        "\n",
        "df = df[~((df < bot_treshold) | (df > top_treshold)).any(axis=1)]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "FFztZRODgSJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Univariate Analysis**\n",
        "Karena target prediksi dari dataset ini ada pada fitur Close_Price yang merupakan harga crypto coin Ethereum, jadi hanya fokus menganalisis korelasi data pada feature tersebut. Dari hasil visualisasi data dibawah dapat disimpulkan bahwa peningkatan harga crypto coin ethereum sebanding dengan penurunan jumlah sampel data."
      ],
      "metadata": {
        "id": "wQwOjHSMuI7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(bins=50, figsize=(15, 10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k0KPBWnZCQjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multivariate Analysis**\n",
        "Jika di lihat dari visualisasi data dibawah. Fitur Close pada sumbu y memiliki korelasi dengan data pada fitur High, Low, Open, dan Marketcap. Korelasi yang terdapat pada data-data tersebut merupakan korelas yang tinggi, sedangkan untuk fitur Volume terlihat memiliki korelasi yang cukup lemah karena sebaran datanya tidak membentuk pola."
      ],
      "metadata": {
        "id": "9oF1ATYly6Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df, diag_kind = 'kde')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yswBTSNkEui1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk lebih jelasnya dapat dilihat melalui visualisasi dibawah yang menunjukkan skor korelasi di tiap fitur dengan fitur Close. Pada fitur High, Low, Open dan Marketcap memiliki skor korelasi yang terbilang tinggi yaitu di atas 0.9. Sedangkan pada fitur Volume memiliki skor korelasi yang cukup rendah yaitu 0.38. Sehingga fitur Volume ini dapat didrop dari dataset."
      ],
      "metadata": {
        "id": "zLdWPSZjmXAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df.corr().round(2)\n",
        " \n",
        "sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix untuk Fitur Numerik \", size=20)"
      ],
      "metadata": {
        "id": "4CkOhq6QGeAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Volume'], axis=1, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "Yb-p6b0AYXfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preparation**\n",
        "\n",
        "---\n",
        "\n",
        "### **Menghapus data yang tidak diperlukan dan merubah nama column**\n",
        "\n",
        "Kolom data seperti (SNo, Name, Symbol, Date, Marketcap) tidak diperlukan untuk pelatihan, karena data tersebut akan mengganggu model dalam mempelajari data. Karena isi dari data tersebut tidak memiliki value yang berarti untuk dipelajari oleh model. Lalu, mengubah nama kolom High, Low, Open, Close menjadi nama kolom yang dapat lebih dipahami.\n"
      ],
      "metadata": {
        "id": "kM__yT9qnYXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unused_columns = ['SNo', 'Name', 'Symbol', 'Date', 'Marketcap']\n",
        "renamed_columns = {'High': 'High_Price', 'Low': 'Low_Price', \n",
        "                   'Open': 'Open_Price', 'Close': 'Close_Price'}\n",
        "\n",
        "df.drop(unused_columns, axis=1, inplace=True)\n",
        "df.rename(columns=renamed_columns, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "uDgnfddVW8tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split dataset**\n",
        "Membagi dataset menjadi data training dan data testing"
      ],
      "metadata": {
        "id": "pLNPEjMJkbCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop(['Close_Price'], axis=1).values\n",
        "y = df['Close_Price'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print(f'Total # of sample in whole dataset: {len(x)}')\n",
        "print(f'Total # of sample in train dataset: {len(x_train)}')\n",
        "print(f'Total # of sample in test dataset: {len(x_test)}')"
      ],
      "metadata": {
        "id": "Q0DdZbjD9Ckq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Normalisasi data**\n",
        "Melakukan transformasi pada data fitur fitur yang akan dipelajari oleh model menggunakan library MinMaxScaler. MinMaxScaler mentransformasikan fitur dengan menskalakan setiap fitur ke rentang tertentu. Library ini menskalakan dan mentransformasikan setiap fitur secara individual sehingga berada dalam rentang yang diberikan pada set pelatihan, pada library ini memiliki range default antara nol dan satu."
      ],
      "metadata": {
        "id": "OWfTh51NoBXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train)"
      ],
      "metadata": {
        "id": "o0verlgS9hW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = pd.DataFrame(columns=['train_mse', 'test_mse'],\n",
        "                      index=['KNN', 'RandomForest', 'SVR'])"
      ],
      "metadata": {
        "id": "JoWItp8o-DPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Development**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Tuning Hyperparameters**\n",
        "Melakukan tuning hyperparameters untuk mendapatkan parameter dengan performa terbaik pada model. Untuk melakukan tuning hyperparameter pada proyek ini menggunakan teknik Grid search. Grid search memungkinkan untuk menguji beberapa parameter sekaligus pada sebuah model. Dengan menerapkan teknik ini kita dapat melihat performa model terbaik dengan parameter tertentu. Hasil dari grid search terkadang berbeda setelah kode dijalankan ulang.\n"
      ],
      "metadata": {
        "id": "zf1R1Mr_qTNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# svr = SVR()\n",
        "# parameters = {\n",
        "#     'kernel': ['rbf'],\n",
        "#     'C':     [1000, 10000, 100000],\n",
        "#     'gamma': [0.3, 0.03, 0.003]\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(\n",
        "#     svr, \n",
        "#     parameters,\n",
        "#     cv=5, \n",
        "#     verbose=1,\n",
        "#     n_jobs=6,\n",
        "# )\n",
        "\n",
        "# grid_search.fit(x_train, y_train)\n",
        "\n",
        "# print(grid_search.best_params_)\n",
        "# print(grid_search.best_score_)"
      ],
      "metadata": {
        "id": "iMavMU3hox11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knn = KNeighborsRegressor()\n",
        "# parameters =  {\n",
        "#     'n_neighbors': range(1, 25),\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(\n",
        "#   knn, \n",
        "#   parameters, \n",
        "#   cv=5,\n",
        "#   verbose=1, \n",
        "#   n_jobs=6,\n",
        "# )\n",
        "\n",
        "# grid_search.fit(x_train, y_train)\n",
        "\n",
        "# print(grid_search.best_params_)\n",
        "# print(grid_search.best_score_)"
      ],
      "metadata": {
        "id": "nQSAR8YC-zkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rf = RandomForestRegressor()\n",
        "# parameters =  {\n",
        "#     'n_estimators': range(1, 10),\n",
        "#     'max_depth': [16, 32, 64],\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(\n",
        "#   rf, \n",
        "#   parameters, \n",
        "#   cv=5,\n",
        "#   verbose=1,\n",
        "#   n_jobs=6,\n",
        "# )\n",
        "# grid_search.fit(x_train, y_train)\n",
        "\n",
        "# print(grid_search.best_params_)\n",
        "# print(grid_search.best_score_)"
      ],
      "metadata": {
        "id": "qAReIGSLoxUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training Model**\n",
        "**Support Vector Machine**"
      ],
      "metadata": {
        "id": "GfQhjwTTtVwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svr = SVR(C=100000, gamma=0.003, kernel='rbf')                          \n",
        "svr.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "V1gSHqbV_z7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Nearest Neighbours**"
      ],
      "metadata": {
        "id": "88skRX9nt5AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "2qIyLGyq-c9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "c0ZAByr6tq0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=6, max_depth=16)\n",
        "rf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "v4iyu22V_JhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Evaluation**"
      ],
      "metadata": {
        "id": "bhzI01rDuHKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "1qF7Iwcu_5EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {'KNN': knn, 'RandomForest': rf, 'SVR': svr}\n",
        "\n",
        "for name, model in model_dict.items():\n",
        "  models.loc[name, 'train_mse'] = mean_squared_error(y_true=y_train, y_pred=model.predict(x_train))\n",
        "  models.loc[name, 'test_mse'] = mean_squared_error(y_true=y_test, y_pred=model.predict(x_test)) \n",
        "\n",
        "models"
      ],
      "metadata": {
        "id": "c08kVYi9BFKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "models.sort_values(by='test_mse', ascending=False).plot(kind='barh', ax=ax, zorder=3)\n",
        "ax.grid(zorder=0)"
      ],
      "metadata": {
        "id": "wixUU4_xb1B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = x_test.copy()\n",
        "predictions = {'y_true':y_test}\n",
        "for name, model in model_dict.items():\n",
        "  predictions['prediction_' + name] = model.predict(test_data)\n",
        " \n",
        "predictions = pd.DataFrame(predictions)\n",
        "predictions"
      ],
      "metadata": {
        "id": "huS2iQAbcPfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions.tail(10)\n",
        "predictions.plot(kind='bar',figsize=(16,10))\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wcIpf3KABKkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari ketiga model yang digunakan. Terlihat bahwa hampir semua model yang digunakan memiliki hasil prediksi mendekati dengan hasil yang sebenarnya."
      ],
      "metadata": {
        "id": "MbvSQ_wFwaR1"
      }
    }
  ]
}